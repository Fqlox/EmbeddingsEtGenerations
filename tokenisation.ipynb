{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenisation, embedding & PCA\n",
    "Ce jupyter notebook montre étape par étape comment produire une cartographie de prompt en ce basant sur l'encodeur CLIP.\n",
    "Pour une liste de prompt définis, nous calculons leurs *embeddings* respectif pour ensuite le réduire à deux dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from transformers import AutoTokenizer, CLIPTextModelWithProjection\n",
    "\n",
    "# Chargement du modèle de tokenisation et d'embedding depuis HG_HUB\n",
    "model = CLIPTextModelWithProjection.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation du matrix prompt \n",
    "On produit des prompts suivant 3 figures : un sujet, des informations de lumières, et des informations sur du détails photographique. On combine ensuite ces bout de phrase pour produire les prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def pipe_to_list(pipe:str):\n",
    "    # Transforme un str de type \"a|b\" en liste [a, b]\n",
    "    return pipe.split(\"|\")\n",
    "\n",
    "subjects = \"A man | a woman | landscape forest | view from the exterior of a cavern | Beautiful landscape, sunset | Montain landscape | city seen from above the ground, skyscraper |   a person with a beautiful smile | crowd of people on the street | Small dog on a couch | a cat next to a window | a space alien \"\n",
    "lights = \"Natural light | hard light | soft light \"\n",
    "photographics = \"Intricate detail, ultra sharp | 50mm | 120mm | long shot | ISO 1000 | ISO 100 | long pose shot | portrait shot | close-up | ultra close-up | long distance shoot | fisheye | 8mm | 16m\"\n",
    "\n",
    "prompts = [pipe_to_list(subjects), pipe_to_list(lights), pipe_to_list(photographics)]\n",
    "\n",
    "\n",
    "\n",
    "prompts_all = []\n",
    "for item in product(*prompts):\n",
    "    prompts_all.append(\", \".join(item))\n",
    "len(prompts_all) # => 504 prompts généré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisation\n",
    "inputs = tokenizer(prompts_all, padding=True, return_tensors=\"pt\")\n",
    "# Embedding\n",
    "outputs = model(**inputs)\n",
    "text_embeds = outputs.text_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_embeds = text_embeds.detach().numpy() # on transforme les embedding de tensor a numpy array\n",
    "pca = PCA(n_components=2) # chargement du pca\n",
    "pca.fit(np_embeds) # On module le PCA en fonction des données fournis.\n",
    "array_2dim  = pca.transform(np_embeds) # On réduit les nombre de dimension des valeurs\n",
    "array_2dim.shape #=> (504, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement des données\n",
    "\n",
    "Pour afficher les données on enregistre les donnés en json sous forme : \n",
    "`[{\"prompt1\" : [x1, y1]}, {\"prompt2\" : [x2, y2]}]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_parse = {}\n",
    "for index, prompt in enumerate(prompts_all):\n",
    "    json_parse[prompt] = array_2dim[index].tolist()\n",
    "\n",
    "with open(\"myPCA.json\", \"w+\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_parse, f, ensure_ascii=True, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
